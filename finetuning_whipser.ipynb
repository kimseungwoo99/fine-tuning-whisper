{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimseungwoo99/fine-tuning-whisper/blob/main/finetuning_whipser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "xY0aXvpuNTWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY3qj3v3dEDs"
      },
      "outputs": [],
      "source": [
        "# 훈련이 끝난 모델을 HuggingFace Hub에 업로드하기 위해 로그인\n",
        "# 비공개 혹은 제한된 공개의 데이터셋에 접근할 경우에도 로그인이 필요하다.\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyGaB7VydR3v"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "# 파인튜닝을 진행하고자 하는 모델의 feature extractor를 로드\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB7sNMgCd2Xx"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "# 파인튜닝을 진행하고자 하는 모델의 tokenizer를 로드\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoPiz2qwd7gZ"
      },
      "outputs": [],
      "source": [
        "input_str = \"안녕하세요. 시작해보겠습니다.\"\n",
        "labels = tokenizer(input_str).input_ids\n",
        "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
        "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input:                 {input_str}\")\n",
        "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
        "print(f\"Decoded w/out special: {decoded_str}\")\n",
        "print(f\"Are equal:             {input_str == decoded_str}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1o2JPvZd_g3"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgrNeSv656MP"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3zZpOgw15dE"
      },
      "outputs": [],
      "source": [
        "# csv 파일을 로드하여 df로 변환\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataframe/df_total.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Bbt8N42Fsv"
      },
      "outputs": [],
      "source": [
        "# Null data 유무 확인\n",
        "df.isnull().values.sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interval 열 삭제\n",
        "df = df.drop('interval', axis=1)"
      ],
      "metadata": {
        "id": "XBOEUk8JLdCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJE1yN-JyeFE"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAShdBwzsiYn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# file_name 열 제외한 나머지 열 전처리\n",
        "columns_to_preprocess = df.columns[df.columns != 'audio_file']  # 'Text' 열을 제외한 열 선택\n",
        "\n",
        "for column in columns_to_preprocess:\n",
        "    df[column] = df[column].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)).replace('\\n', ' ').strip())  # 정규식을 사용하여 전처리 및 공백 제거\n",
        "\n",
        "\n",
        "# 전처리된 데이터프레임 출력\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tac82uOW7Mjx"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDKi2aiE7OYo"
      },
      "outputs": [],
      "source": [
        "# 오디오 파일 경로를 dict의 \"audio\" 키의 value로 넣고 이를 데이터셋으로 변환\n",
        "# 이때, Whisper가 요구하는 사양대로 Sampling rate는 16,000으로 설정한다.\n",
        "ds = Dataset.from_dict({\"audio\": [path for path in df[\"audio_file\"]],\n",
        "                       \"Text\": [transcript for transcript in df[\"sentence\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnbJQN5Z7RJ_"
      },
      "outputs": [],
      "source": [
        "# 데이터셋을 훈련 데이터와 테스트 데이터, 밸리데이션 데이터로 분할\n",
        "train_testvalid = ds.train_test_split(test_size=0.2)\n",
        "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
        "datasets = DatasetDict({\n",
        "    \"train\": train_testvalid[\"train\"],\n",
        "    \"test\": test_valid[\"test\"],\n",
        "    \"valid\": test_valid[\"train\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Ru2xQMBl0z"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # 오디오 파일을 16kHz로 로드\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # input audio array로부터 log-Mel spectrogram 변환\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # target text를 label ids로 변환\n",
        "    batch[\"labels\"] = tokenizer(batch[\"Text\"]).input_ids\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRcbJ2-HBnDN"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리 함수를 데이터셋 전체에 적용\n",
        "low_call_voices = datasets.map(prepare_dataset, remove_columns=datasets.column_names[\"train\"], num_proc=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bGt5yMrEjnH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "low_call_voices = datasets.load_from_disk(\"/content/drive/MyDrive/hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbYpWb3pIAp4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Iu5NBcIDhg"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n",
        "        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # Tokenize된 레이블 시퀀스를 가져온다.\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n",
        "        # 해당 토큰은 이후 언제든 추가할 수 있다.\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4dlFXvDIF1R"
      },
      "outputs": [],
      "source": [
        "# 훈련시킬 모델의 processor, tokenizer, feature extractor 로드\n",
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-wFQ6DhIGtp"
      },
      "outputs": [],
      "source": [
        "# 데이터 콜레이터 초기화\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxQd5SX9IIhr"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load('cer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y05ccLHPILfK"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # pad_token을 -100으로 치환\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vZemox-IOb-"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe4yaf0jITu-"
      },
      "outputs": [],
      "source": [
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBknuOczIVJN"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,  # epoch 대신 설정\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnHKyQ_rIoy5"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"valid\"],  # or \"test\"\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoWAZbxiIu4a"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzxbmVXmKKEJ"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"https://huggingface.co/datasets/aoome123/important\",\n",
        "    \"dataset\": \"important\",  # a 'pretty' name for the training dataset\n",
        "    \"dataset_args\": \"config: ko, split: valid\",\n",
        "    \"language\": \"ko\",\n",
        "    \"model_name\": \"ft_model\",  # a 'pretty' name for your model\n",
        "    \"finetuned_from\": \"openai/whisper-base\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": \"hf-asr-leaderboard\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh6xU1_uQqxb"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zosXEq7DQr4Y"
      },
      "outputs": [],
      "source": [
        "processor.push_to_hub(\"repo_name\")\n",
        "tokenizer.push_to_hub(\"repo_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qRslLpoi_Cl"
      },
      "outputs": [],
      "source": [
        "# 파인 튜닝한 모델을 로드\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
        "\n",
        "fine_model = WhisperForConditionalGeneration.from_pretrained(\"aoome123/repo_name\")\n",
        "\n",
        "\n",
        "fine_feature_extractor = WhisperFeatureExtractor.from_pretrained(\"aoome123/repo_name\")\n",
        "fine_tokenizer = WhisperTokenizer.from_pretrained(\"aoome123/repo_name\", language=\"Korean\", task=\"transcribe\")\n",
        "fine_processor = WhisperProcessor.from_pretrained(\"aoome123/repo_name\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPtcHMrekWwq"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZgVyO17kZtl"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=fine_model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"valid\"],  # for evaluation(not validation)\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=fine_processor.feature_extractor,  # 수정된 부분\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc73aubAmw2_"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate() # 기존 whisper-base 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUO9t-6-kbds"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate() # 파인 튜닝된 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "666mg2gbj6Wj"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=fine_processor.feature_extractor,\n",
        "    model=fine_model,\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMkypLZDpV5q"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    model=model,\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBABQ1hzR5vu"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "small_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "small_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "small_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=small_processor.feature_extractor,  # fine_processor.feature_extractor 대신 tokenizer 사용\n",
        "    model=small_model,  # fine_model 대신 base_model 사용\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dgnV1nqRxOv"
      },
      "outputs": [],
      "source": [
        "# small 모델\n",
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "tiny_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "tiny_trainer = Seq2SeqTrainer(\n",
        "    model=tiny_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=low_call_voices['test'],  # 평가 데이터셋\n",
        "    compute_metrics=compute_metrics,  # 평가 메트릭 계산 함수\n",
        "    tokenizer=small_processor,  # processor로 변경\n",
        "    data_collator= small_data_collator # 데이터 패딩,\n",
        ")\n",
        "\n",
        "\n",
        "# tiny 모델 평가\n",
        "tiny_eval_result = tiny_trainer.evaluate()\n",
        "print(tiny_eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFY38Kb8qRoX"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "base_processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")\n",
        "base_tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "base_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=base_processor.feature_extractor,  # fine_processor.feature_extractor 대신 tokenizer 사용\n",
        "    model=base_model,  # fine_model 대신 base_model 사용\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aQOo2_-ozDv"
      },
      "outputs": [],
      "source": [
        "# base 모델\n",
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "base_trainer = Seq2SeqTrainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=low_call_voices['test'],  # 평가 데이터셋\n",
        "    compute_metrics=compute_metrics,  # 평가 메트릭 계산 함수\n",
        "    tokenizer=base_processor,  # processor로 변경\n",
        "    data_collator= base_data_collator # 데이터 패딩,\n",
        ")\n",
        "\n",
        "\n",
        "# base 모델 평가\n",
        "base_eval_result = base_trainer.evaluate()\n",
        "print(base_eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg_cne4mWb-A"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "medium_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")\n",
        "medium_processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"Korean\", task=\"transcribe\")\n",
        "medium_tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"Korean\", task=\"transcribe\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")\n",
        "\n",
        "medium_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=medium_processor.feature_extractor,\n",
        "    model=medium_model,  # fine_model 대신 medium_model 사용\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYhJIP4wWXzn"
      },
      "outputs": [],
      "source": [
        "# medium 모델\n",
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "medium_trainer = Seq2SeqTrainer(\n",
        "    model=medium_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=low_call_voices['test'],  # 평가 데이터셋\n",
        "    compute_metrics=compute_metrics,  # 평가 메트릭 계산 함수\n",
        "    tokenizer=medium_processor,\n",
        "    data_collator= medium_data_collator # 데이터 패딩,\n",
        ")\n",
        "\n",
        "\n",
        "# base 모델 평가\n",
        "medium_eval_result = medium_trainer.evaluate()\n",
        "print(medium_eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUOmVLTwuGFN"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxQrSwfRanj_"
      },
      "outputs": [],
      "source": [
        "fine_model = WhisperForConditionalGeneration.from_pretrained(\"aoome123/repo_name\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"aoome123/repo_name\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"aoome123/repo_name\", language=\"Korean\", task=\"transcribe\")\n",
        "fine_processor = WhisperProcessor.from_pretrained(\"aoome123/repo_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0z5udQ1xVu_"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "fine_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=fine_processor.feature_extractor,  # fine_processor.feature_extractor 대신 tokenizer 사용\n",
        "    model=fine_model,  # fine_model 대신 base_model 사용\n",
        "    padding='longest',\n",
        "    pad_to_multiple_of=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51gcM3kPxJPl"
      },
      "outputs": [],
      "source": [
        "# fine-tuning 모델\n",
        "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "fine_model = WhisperForConditionalGeneration.from_pretrained(\"aoome123/repo_name\")\n",
        "fine_trainer = Seq2SeqTrainer(\n",
        "    model=fine_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=low_call_voices['test'],  # 평가 데이터셋\n",
        "    compute_metrics=compute_metrics,  # 평가 메트릭 계산 함수\n",
        "    tokenizer=fine_processor,\n",
        "    data_collator= fine_data_collator # 데이터 패딩,\n",
        ")\n",
        "\n",
        "\n",
        "# fine_tuning 모델 평가\n",
        "fine_eval_result = fine_trainer.evaluate()\n",
        "print(fine_eval_result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1QPAnphN22HSWwMdbh7s0r8nk01D5W1lB",
      "authorship_tag": "ABX9TyM8bFdntQS1l5hqPMnDrSRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}